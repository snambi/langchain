{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4912fd56-e8a5-4bc1-982c-f7c84eb22b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from secret_key import openapi_key\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key\n",
    "\n",
    "#print(openapi_key)\n",
    "print(os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f3c033-794b-4947-b8b7-ca45cb03a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated name: \"Khazana Khaas\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains.llm import LLMChain\n",
    "import json\n",
    "\n",
    "\n",
    "model = OllamaLLM(model=\"llama3.2:1b\", temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables= ['cuisine'],\n",
    "    template = \"I want to open an restaurent for {cuisine} food. Suggest a fancy name. Return only one name without any other text\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine=\"Mexican\")\n",
    "\n",
    "name_chain = LLMChain(llm=model, prompt=prompt_template_name)\n",
    "\n",
    "o = name_chain.invoke(\"Gujarati\")\n",
    "\n",
    "outjson = json.loads( json.dumps(o))\n",
    "\n",
    "print( \"generated name: \" + outjson['text'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a42f0a-2492-4e04-951c-8ce1e961c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables= ['restaurant_name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=model, prompt=prompt_template_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5041ed47-0657-4fa7-b55c-4a3c3d6480b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some menu item suggestions for Spicehaven:\n",
      "\n",
      "Spicy Shrimp and Chorizo Paella, Currywurst Burger with Spicy Mayo, Jamaican Jerk Chicken Tenders with Mango Slaw, Ghost Pepper Wings with Blue Cheese Dip, Thai Green Curry Risotto Bowl with Shrimp and Vegetables, Indian Butter Chicken Naan Bites with Cucumber Raita, Korean BBQ Beef Tacos with Kimchi Slaw, Sri Lankan Fish Ambulthiyal (Sour Soup) with Crusty Bread, Jamaican Jerk Pork Belly Buns with Spicy Pickle Relish.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain] )\n",
    "\n",
    "response = chain.run(\"Indian\")\n",
    "print( response )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bfe488c-8785-4f4d-9978-efeb59d3a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name2 = PromptTemplate(\n",
    "    input_variables= ['cuisine'],\n",
    "    template = \"I want to open an restaurent for {cuisine} food. Suggest a fancy name. Return only one name without any other text\"\n",
    ")\n",
    "\n",
    "prompt_template_name2.format(cuisine=\"Mexican\")\n",
    "\n",
    "name_chain2 = LLMChain(llm=model, prompt=prompt_template_name2, output_key=\"restaurant_name\")\n",
    "\n",
    "prompt_template_items2 = PromptTemplate(\n",
    "    input_variables= ['restaurant_name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "\n",
    "food_items_chain2 = LLMChain(llm=model, prompt=prompt_template_items2, output_key=\"menu_items\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d468539a-5df7-4b67-ba3a-d732a6122a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'arabic',\n",
       " 'restaurant_name': '\"Al-Furqan Al-Khaleesi\"',\n",
       " 'menu_items': 'Here are some menu item suggestions for \"Al-Furqan Al-Khaleesi\" (The Golden Standard of Hospitality):\\n\\nMeat dishes: lamb koftas, chicken shawarma, grilled fish with tahini sauce, kebabs of beef or lamb, shwarma-style lamb burgers.\\n\\nVegetarian options: falafel wraps, grilled eggplant parmesan, roasted vegetables with hummus, stuffed bell peppers, tabbouleh salad.\\n\\nSides and accompaniments: pickled turnips, preserved lemon, olives, flatbread with olive oil and herbs, grilled pita bread with tzatziki sauce.\\n\\nDesserts: baklava, ma\\'amoul cookies, fresh fruit platter with honey and pistachios.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.sequential import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain2, food_items_chain2],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', 'menu_items' ]\n",
    ")\n",
    "\n",
    "chain.invoke({'cuisine':'arabic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5bdeae4-6931-4313-ad14-13b80b54d8db",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m wikipedia \u001b[38;5;241m=\u001b[39m WikipediaAPIWrapper()\n\u001b[1;32m      8\u001b[0m wikipedia_tool \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWikipedia\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m : WikipediaAPIWrapper(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_key\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 15\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mload_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwikipedia_tool\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm-math\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(\n\u001b[1;32m     18\u001b[0m     tools,\n\u001b[1;32m     19\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen was Elon musk born? what his age right now in 2025?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/github/snambi/langchain/example1/venv/lib/python3.11/site-packages/langchain_community/agent_toolkits/load_tools.py:712\u001b[0m, in \u001b[0;36mload_tools\u001b[0;34m(tool_names, llm, callbacks, allow_dangerous_tools, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m _handle_callbacks(\n\u001b[1;32m    709\u001b[0m     callback_manager\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m), callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[1;32m    710\u001b[0m )\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m tool_names:\n\u001b[0;32m--> 712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDANGEROUS_TOOLS\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_tools:\n\u001b[1;32m    713\u001b[0m         raise_dangerous_tools_exception(name)\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequests\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.tools import Tool, DuckDuckGoSearchRun, ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "wikiTool= Tool(  \n",
    "     name=\"Wikipedia\",  \n",
    "     func=wiki.run,  \n",
    "     description=\"useful when you need an answer about encyclopedic general knowledge\"  \n",
    " )\n",
    "\n",
    "tools = [wikiTool]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    model,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    allow_dangerous_tools=[wikipedia_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"When was Elon musk born? what his age right now in 2025?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904556c-93d1-4c92-b5fc-60a252e0dcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
