{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4912fd56-e8a5-4bc1-982c-f7c84eb22b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from secret_key import openapi_key\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key\n",
    "\n",
    "#print(openapi_key)\n",
    "print(os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0f3c033-794b-4947-b8b7-ca45cb03a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated name: \"Rangoli Bhojan\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.chains.llm import LLMChain\n",
    "import json\n",
    "\n",
    "\n",
    "model = OllamaLLM(model=\"llama3.2:1b\", temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables= ['cuisine'],\n",
    "    template = \"I want to open an restaurent for {cuisine} food. Suggest a fancy name. Return only one name without any other text\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine=\"Mexican\")\n",
    "\n",
    "name_chain = LLMChain(llm=model, prompt=prompt_template_name)\n",
    "\n",
    "o = name_chain.invoke(\"Gujarati\")\n",
    "\n",
    "outjson = json.loads( json.dumps(o))\n",
    "\n",
    "print( \"generated name: \" + outjson['text'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8a42f0a-2492-4e04-951c-8ce1e961c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables= ['restaurant_name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comma separated list\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=model, prompt=prompt_template_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5041ed47-0657-4fa7-b55c-4a3c3d6480b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1c/qhgrw9893vq3807zpmk8684m0000gn/T/ipykernel_41372/2171301943.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(\"Indian\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some menu item suggestions for \"Spice & Sage\":\n",
      "\n",
      "Grilled Chicken Fajitas with Sauteed Onions and Bell Peppers, Spiced Apple Cider Braised Short Ribs, Sage and Garlic Mashed Potatoes, Herb-Roasted Salmon with Lemon Butter, Spicy Chorizo and Manchego Empanadas, Roasted Vegetable Quinoa Bowl with Crispy Sage Leaves.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain] )\n",
    "\n",
    "response = chain.run(\"Indian\")\n",
    "print( response )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe488c-8785-4f4d-9978-efeb59d3a089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
